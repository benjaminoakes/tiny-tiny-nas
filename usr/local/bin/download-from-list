#!/bin/sh
set -o errexit

# Some sites give 403 Forbidden to the wget User-Agent
version="0.1"
user_agent="TinyTinyNAS/$version ($(uname -m) $(uname -s))"

show_usage() {
  cat <<EOF
Usage: $0 lock_path csv_url destination [max_age_days]

Download files specified in a remote CSV file to the given destination.
Existing files are skipped.

The CSV has the format filename,url.  Very little parsing is done; only simple
comma separated values are allowed.

Example:

    $0 http://www.example.com/download.csv ~/Downloads/
EOF

  exit 1
}

# Fetch downloads given from a CSV
#
# Format: name,url
download_listed() {
  local first=1
  local name clean_name url

  # No parsing beyond splitting on comma
  while IFS=',' read name url; do
    clean_name=$(echo $name | sed 's/[?\/]/_/g')

    # Skip header
    if [ 0 -eq $first ]; then
      if [ -f "$clean_name" ]; then
        echo "File exists, skipping $clean_name"
      else
        wget --user-agent "$user_agent" "$url" -O "$clean_name.download"
        mv -v "$clean_name.download" "$clean_name"

        # Force updated mtime for max_age_days
        touch "$clean_name"

        checksum "$clean_name"
        unzip_if_zipfile "$clean_name"
      fi
    fi

    first=0
  done
}

# Automatically compute checksums
checksum() {
  local path="$1"

  md5sum "$clean_name" >> MD5SUMS
  sha1sum "$clean_name" >> SHA1SUMS
  sha256sum "$clean_name" >> SHA256SUMS
}


# Automatically unzip .zip files
#
# We could also untar, but that's rarely useful.  Developers tend to use .tgz
# for lots of small files (e.g. source code) and .zip files for bundled up
# larger files (like MP3 albums, etc).
unzip_if_zipfile() {
  local path="$1"

  # If the extension is .zip
  if [ "$(basename "$path" .zip)" != "$(basename "$path")" ]; then
    unzip -d "$(basename "$path" .zip)" "$path"
  fi
}

get_list_and_download() {
  # There's a bug with `wget -q`, so we download to a file instead.
  wget --user-agent "$user_agent" -O "$tmp_list" "$csv_url"

  mkdir -p "$destination"

  if [ "$max_age_days" != "" ]; then
    find "$destination" -type f -mtime +$max_age_days -exec rm -rfv {} \;
  fi

  cd "$destination"
  download_listed < "$tmp_list"

  rm -f "$tmp_list"
}

main() {
  lock_path="$1"
  csv_url="$2"
  destination="$3"
  max_age_days="$4"
  tmp_list=$(mktemp)

  # Use a lock dir instead of a lock file because mkdir is atomic
  # http://stackoverflow.com/questions/185451/quick-and-dirty-way-to-ensure-only-one-instance-of-a-shell-script-is-running-at
  if ! mkdir "$lock_path" 2>/dev/null; then
    echo "$0: already running with $lock_path" >&2
    exit 1
  fi

  if [ "$csv_url" = "" ] || [ "$destination" = "" ]; then
    show_usage
  else
    get_list_and_download
  fi

  rmdir "$lock_path"
}

main $@
